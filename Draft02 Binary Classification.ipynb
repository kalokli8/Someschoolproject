{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weatherAUS.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = \"RISK_MM\" )\n",
    "df = df.drop(columns = \"Evaporation\")\n",
    "df = df.drop(columns = \"Sunshine\")\n",
    "df = df.drop(columns = \"Cloud9am\")\n",
    "df = df.drop(columns = \"Cloud3pm\")\n",
    "df = df.drop(columns = \"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seaborn to conduct heatmap to identify missing data\n",
    "# data -> argument refers to the data to creat heatmap\n",
    "# yticklabels -> argument avoids plotting the column names\n",
    "# cbar -> argument identifies if a colorbar is required or not\n",
    "# cmap -> argument identifies the color of the heatmap\n",
    "sns.heatmap(data = missing_values, yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GeluvcH/anaconda3/envs/FTDS/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/GeluvcH/anaconda3/envs/FTDS/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/GeluvcH/anaconda3/envs/FTDS/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/GeluvcH/anaconda3/envs/FTDS/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/GeluvcH/anaconda3/envs/FTDS/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/GeluvcH/anaconda3/envs/FTDS/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Adelaide', 'Albury', 'AliceSprings', 'BadgerysCreek', 'Ballarat',\n",
       "       'Bendigo', 'Brisbane', 'Cairns', 'Canberra', 'Cobar',\n",
       "       'CoffsHarbour', 'Dartmoor', 'Darwin', 'GoldCoast', 'Hobart',\n",
       "       'Katherine', 'Launceston', 'Melbourne', 'MelbourneAirport',\n",
       "       'Mildura', 'Moree', 'MountGambier', 'Nhil', 'NorahHead',\n",
       "       'NorfolkIsland', 'Nuriootpa', 'PearceRAAF', 'Perth',\n",
       "       'PerthAirport', 'Portland', 'Richmond', 'Sale', 'Sydney',\n",
       "       'SydneyAirport', 'Townsville', 'Tuggeranong', 'Uluru',\n",
       "       'WaggaWagga', 'Walpole', 'Watsonia', 'Williamtown', 'Witchcliffe',\n",
       "       'Wollongong', 'Woomera'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class is a categorical variable - will need to convert to numerical for classification algorithm \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df[\"rain_tomorrow\"] = encoder.fit_transform(df[\"RainTomorrow\"])\n",
    "df[\"rain_today\"] = encoder.fit_transform(df[\"RainToday\"])\n",
    "df['windgus_dir'] = encoder.fit_transform(df[\"WindGustDir\"])\n",
    "df['winddir_9am'] = encoder.fit_transform(df[\"WindDir9am\"])\n",
    "df['winddir_3pm'] = encoder.fit_transform(df[\"WindDir3pm\"])\n",
    "df['location'] = encoder.fit_transform(df[\"Location\"])\n",
    "\n",
    "\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GeluvcH/anaconda3/envs/FTDS/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see what the encoder represents\n",
    "df[\"rain_tomorrow\"] = encoder.fit_transform(df[\"RainTomorrow\"])\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# response vector in a object named y\n",
    "y = df[\"rain_tomorrow\"]\n",
    "# Feature matrix in a object named X\n",
    "X = df.drop(columns=[\"rain_tomorrow\", \"RainTomorrow\",\"RainToday\",\"WindGustDir\",\"WindDir9am\",\"WindDir3pm\", \"Location\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Humidity3pm', 'Sunshine', 'Pressure3pm', 'WindGustSpeed', 'Cloud3pm','Pressure9am'\n",
    "#y = df[\"rain_tomorrow\"]\n",
    "#X = df[[\"Humidity3pm\", \"Pressure3pm\", \"WindGustSpeed\", \"Cloud3pm\", \"Pressure9am\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112925, 17)\n",
      "(112925,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and test sets (80:20)\n",
    "\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90340, 17)\n",
      "(22585, 17)\n",
      "(90340,)\n",
      "(22585,)\n"
     ]
    }
   ],
   "source": [
    "#shape of train and test objects\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# shape of new y objects\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the KNeighborsClassifier class from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#import metrics model to check the accuracy \n",
    "from sklearn import metrics\n",
    "#Try running from k=1 through 25 and record testing accuracy\n",
    "k_range = range(1,26)\n",
    "scores = {}\n",
    "scores_list = []\n",
    "for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train,y_train)\n",
    "        y_pred=knn.predict(X_test)\n",
    "        scores[k] = metrics.accuracy_score(y_test,y_pred)\n",
    "        scores_list.append(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing accuracy for each value of K\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the relationship between K and the testing accuracy\n",
    "plt.plot(k_range,scores_list)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 21)\n",
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the KNeighborsClassifier class from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#import metrics model to check the accuracy \n",
    "from sklearn import metrics\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GeluvcH/anaconda3/envs/FTDS/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01215358 -0.00587283  0.00865313  0.07105698 -0.01737968 -0.04060236\n",
      "   0.00305997  0.07023144 -0.0072804  -0.01882137 -0.0250046   0.0303565\n",
      "   0.44319534  0.01092552 -0.03077556 -0.00657627 -0.00712226]]\n",
      "[19.06164731]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GeluvcH/anaconda3/envs/FTDS/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import module for fitting\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create instance (i.e. object) of LogisticRegression\n",
    "logmodel = LogisticRegression(penalty = \"l1\")\n",
    "\n",
    "# Fit the model using the training data\n",
    "# X_train -> parameter supplies the data features\n",
    "# y_train -> parameter supplies the target labels\n",
    "logmodel.fit(X_train, y_train)\n",
    "print(logmodel.coef_)\n",
    "print(logmodel.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the target for test data\n",
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     17609\n",
      "           1       0.74      0.49      0.59      4976\n",
      "\n",
      "    accuracy                           0.85     22585\n",
      "   macro avg       0.80      0.72      0.75     22585\n",
      "weighted avg       0.84      0.85      0.84     22585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = logmodel\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n",
    "solver = ['liblinear', 'saga']\n",
    "\n",
    "param_grid = dict(penalty=penalty,\n",
    "                  C=C,\n",
    "                  class_weight=class_weight,\n",
    "                  solver=solver)\n",
    "\n",
    "grid = GridSearchCV(estimator=logistic,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='roc_auc',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module for fitting\n",
    "from sklearn.svm import LinearSVC\n",
    "# Create instance (i.e. object) of LogisticRegression\n",
    "model = LinearSVC()\n",
    "# Fit the model using the training data\n",
    "# X_train -> parameter supplies the data features\n",
    "# y_train -> parameter supplies the target labels\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the target for test data\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module for fitting\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtreemodel = DecisionTreeClassifier()\n",
    "# Fit the model using the training data\n",
    "# X_train -> parameter supplies the data features\n",
    "# y_train -> parameter supplies the target labels\n",
    "dtreemodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtreemodel.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtreemodel.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train.columns\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dtreemodel.feature_importances_\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = [16, 10] #default figure size\n",
    "sns.barplot( x = a,y = b ,palette=\"Blues_d\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the target for test data\n",
    "predictions = dtreemodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test[0:3])\n",
    "print(predictions[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X.columns\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our trained model as a .dot file\n",
    "from sklearn import tree\n",
    "with open(\"tree1.dot\", 'w') as f:\n",
    "     f = tree.export_graphviz(dtreemodel,\n",
    "                              out_file=f,\n",
    "                              max_depth = 10,\n",
    "                              impurity = True,\n",
    "                              feature_names= Z,\n",
    "                              class_names=[\"No\", \"Yes\"],\n",
    "                              rounded = True,\n",
    "                              filled= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import check_call\n",
    "check_call(['dot', '-Tpng', 'tree1.dot', '-o', 'tree1.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtreemodel.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of values to try for max_depth:\n",
    "max_depth_range = list(range(1, 20))\n",
    "# List to store the accuracy for each value of max_depth:\n",
    "accuracy = []\n",
    "for depth in max_depth_range:\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth = depth, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    accuracy.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(max_depth_range,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module for fitting\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "dtreemodel = DecisionTreeClassifier(max_depth=5)\n",
    "# Fit the model using the training data\n",
    "# X_train -> parameter supplies the data features\n",
    "# y_train -> parameter supplies the target labels\n",
    "dtreemodel.fit(X_train, y_train)\n",
    "\n",
    "predictions = dtreemodel.predict(X_test)\n",
    "print(f\"{accuracy_score(y_test, predictions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtreemodel.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtreemodel.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = dict(zip(a, b))\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2 = weather.copy()\n",
    "for k in weather:\n",
    "    if weather[k] <0.03:\n",
    "        del weather2[k]\n",
    "\n",
    "weather2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"rain_tomorrow\"]\n",
    "# Feature matrix in a object named X\n",
    "\n",
    "X = df[[\"MaxTemp\",\"Evaporation\", \"Sunshine\", \"WindGustSpeed\", \"WindSpeed3pm\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\", \"Temp9am\", \"Temp3pm\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and test sets (80:20)\n",
    "\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of train and test objects\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# shape of new y objects\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module for fitting\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create instance (i.e. object) of LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "\n",
    "# Fit the model using the training data\n",
    "# X_train -> parameter supplies the data features\n",
    "# y_train -> parameter supplies the target labels\n",
    "logmodel.fit(X_train, y_train)\n",
    "print(logmodel.coef_)\n",
    "print(logmodel.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the target for test data\n",
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
